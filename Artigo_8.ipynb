{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQjDTn4HIfjrrZwR4wtvUq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rondinell/Intelig-ncia-Artificial/blob/main/Artigo_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJRUfNp2Gn67",
        "outputId": "c4f83af7-39bf-41b6-f144-950922d5e6d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gnews in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
            "Requirement already satisfied: feedparser~=6.0.2 in /usr/local/lib/python3.11/dist-packages (from gnews) (6.0.11)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.9.3 in /usr/local/lib/python3.11/dist-packages (from gnews) (4.13.4)\n",
            "Requirement already satisfied: dnspython in /usr/local/lib/python3.11/dist-packages (from gnews) (2.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from gnews) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.9.3->gnews) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.9.3->gnews) (4.14.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser~=6.0.2->gnews) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->gnews) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->gnews) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->gnews) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->gnews) (2025.4.26)\n",
            "--- Iniciando a coleta de not칤cias para Bolsa de valores de SP ---\n",
            "Coletados 50 artigos sobre 'Bolsa de valores de SP'.\n",
            "\n",
            "--- Primeiros artigos coletados ---\n",
            "         Data                                             Titulo  \\\n",
            "0  2025-06-16  D칩lar recua e vai a R$ 5,49, em semana de Copo...   \n",
            "1  2025-06-12  Bolsa oscila e d칩lar fica est치vel ap칩s divulga...   \n",
            "2  2025-04-07  Bolsa brasileira tem 3춹 queda seguida em meio ...   \n",
            "3  2025-05-20  Bolsa volta a bater recorde e supera os 140 mi...   \n",
            "4  2025-03-14  Deputados acompanham leil칚o de rodovias estadu...   \n",
            "\n",
            "                               Conteudo para Analise  Link  \n",
            "0  D칩lar recua e vai a R$ 5,49, em semana de Copo...  None  \n",
            "1  Bolsa oscila e d칩lar fica est치vel ap칩s divulga...  None  \n",
            "2  Bolsa brasileira tem 3춹 queda seguida em meio ...  None  \n",
            "3  Bolsa volta a bater recorde e supera os 140 mi...  None  \n",
            "4  Deputados acompanham leil칚o de rodovias estadu...  None  \n",
            "\n",
            "--- Iniciando a an치lise de sentimento dos artigos ---\n",
            "\n",
            "--- An치lise de Sentimento Conclu칤da ---\n",
            "\n",
            "--- DataFrame com Sentimento ---\n",
            "         Data                                             Titulo  \\\n",
            "0  2025-06-16  D칩lar recua e vai a R$ 5,49, em semana de Copo...   \n",
            "1  2025-06-12  Bolsa oscila e d칩lar fica est치vel ap칩s divulga...   \n",
            "2  2025-04-07  Bolsa brasileira tem 3춹 queda seguida em meio ...   \n",
            "3  2025-05-20  Bolsa volta a bater recorde e supera os 140 mi...   \n",
            "4  2025-03-14  Deputados acompanham leil칚o de rodovias estadu...   \n",
            "\n",
            "                               Conteudo para Analise  Link  compound_score  \\\n",
            "0  D칩lar recua e vai a R$ 5,49, em semana de Copo...  None          -0.296   \n",
            "1  Bolsa oscila e d칩lar fica est치vel ap칩s divulga...  None           0.000   \n",
            "2  Bolsa brasileira tem 3춹 queda seguida em meio ...  None           0.000   \n",
            "3  Bolsa volta a bater recorde e supera os 140 mi...  None           0.000   \n",
            "4  Deputados acompanham leil칚o de rodovias estadu...  None           0.000   \n",
            "\n",
            "  sentimento  \n",
            "0   Negativo  \n",
            "1     Neutro  \n",
            "2     Neutro  \n",
            "3     Neutro  \n",
            "4     Neutro  \n",
            "\n",
            "--- Resumo da An치lise de Sentimento ---\n",
            "sentimento\n",
            "Neutro      43\n",
            "Negativo     4\n",
            "Positivo     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Sentimento por Dia ---\n",
            "sentimento  Negativo  Neutro  Positivo\n",
            "Data                                  \n",
            "2024-08-19         0       1         0\n",
            "2024-11-01         0       1         0\n",
            "2024-11-04         0       1         0\n",
            "2024-12-06         0       2         0\n",
            "2024-12-11         1       1         0\n",
            "2024-12-18         0       1         0\n",
            "2024-12-22         0       1         0\n",
            "2024-12-26         0       1         0\n",
            "2024-12-30         0       2         0\n",
            "2025-01-02         0       1         0\n",
            "2025-01-09         0       1         0\n",
            "2025-01-14         0       1         0\n",
            "2025-02-12         0       1         0\n",
            "2025-02-20         0       1         0\n",
            "2025-02-21         1       0         0\n",
            "2025-02-24         0       1         0\n",
            "2025-03-03         0       1         0\n",
            "2025-03-10         0       3         0\n",
            "2025-03-13         0       1         0\n",
            "2025-03-14         0       1         0\n",
            "2025-03-17         0       1         0\n",
            "2025-03-21         0       1         0\n",
            "2025-03-26         0       1         0\n",
            "2025-03-27         0       0         1\n",
            "2025-04-04         0       1         0\n",
            "2025-04-07         0       1         0\n",
            "2025-04-24         0       1         0\n",
            "2025-05-13         0       2         0\n",
            "2025-05-15         0       2         1\n",
            "2025-05-19         0       2         1\n",
            "2025-05-20         0       1         0\n",
            "2025-05-21         1       0         0\n",
            "2025-05-26         0       1         0\n",
            "2025-05-28         0       1         0\n",
            "2025-06-03         0       1         0\n",
            "2025-06-12         0       1         0\n",
            "2025-06-13         0       3         0\n",
            "2025-06-16         1       0         0\n"
          ]
        }
      ],
      "source": [
        "!pip install gnews\n",
        "import pandas as pd\n",
        "from gnews import GNews\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Baixa o l칠xico VADER (necess치rio para a an치lise de sentimento)\n",
        "try:\n",
        "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('vader_lexicon')\n",
        "\n",
        "# --- PARTE 1: COLETANDO NOT칈CIAS COM GNEWS ---\n",
        "\n",
        "print(\"--- Iniciando a coleta de not칤cias para Bolsa de valores de SP ---\")\n",
        "\n",
        "# 游댌 Defina o termo de busca para a a칞칚o da Embraer\n",
        "termo_busca = \"Bolsa de valores de SP\" # Usaremos este termo para buscar not칤cias\n",
        "\n",
        "# Configura칞칫es do GNews\n",
        "# Voc칡 pode ajustar o idioma, o pa칤s e o n칰mero de artigos\n",
        "google_news = GNews(language='pt', country='BR', max_results=50) # Coleta at칠 50 not칤cias\n",
        "\n",
        "# Lista para armazenar os artigos\n",
        "artigos = []\n",
        "\n",
        "try:\n",
        "    # Busca por not칤cias relacionadas ao termo\n",
        "    json_response = google_news.get_news(termo_busca)\n",
        "\n",
        "    # Verifica se a resposta n칚o est치 vazia e processa os artigos\n",
        "    if json_response:\n",
        "        for article in json_response:\n",
        "            # Pegamos o 'title' e o 'description' (se houver) para an치lise de sentimento\n",
        "            # A descri칞칚o pode ser o conte칰do mais relevante para o sentimento\n",
        "            texto_para_analise = article.get('description', '')\n",
        "            if not texto_para_analise: # Se n칚o houver descri칞칚o, usa o t칤tulo\n",
        "                texto_para_analise = article.get('title', '')\n",
        "\n",
        "            # Adiciona a data da publica칞칚o, t칤tulo e o texto para an치lise\n",
        "            # A data precisa de um tratamento se for string (normalmente vem assim)\n",
        "            publicado_em = article.get('published date')\n",
        "            try:\n",
        "                # Tenta converter a data. O formato pode variar, ent칚o 칠 bom ter um try-except.\n",
        "                # Exemplo de formato: 'Mon, 10 Jun 2024 16:30:00 GMT'\n",
        "                data_limpa = datetime.strptime(publicado_em, '%a, %d %b %Y %H:%M:%S %Z').date()\n",
        "            except (ValueError, TypeError):\n",
        "                data_limpa = None # Ou data.today() se preferir um default\n",
        "\n",
        "            artigos.append([\n",
        "                data_limpa,\n",
        "                article.get('title'),\n",
        "                texto_para_analise,\n",
        "                article.get('link')\n",
        "            ])\n",
        "    else:\n",
        "        print(\"Nenhuma not칤cia encontrada para o termo especificado.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro ao coletar not칤cias: {e}\")\n",
        "    print(\"Verifique sua conex칚o com a internet ou se o GNews est치 funcionando corretamente.\")\n",
        "\n",
        "# Criando dataframe com os artigos\n",
        "df = pd.DataFrame(artigos, columns=['Data', 'Titulo', 'Conteudo para Analise', 'Link'])\n",
        "\n",
        "# Remove linhas onde 'Conteudo para Analise' est치 vazio\n",
        "df.replace('', pd.NA, inplace=True)\n",
        "df.dropna(subset=['Conteudo para Analise'], inplace=True)\n",
        "\n",
        "print(f\"Coletados {len(df)} artigos sobre '{termo_busca}'.\")\n",
        "print(\"\\n--- Primeiros artigos coletados ---\")\n",
        "print(df.head())\n",
        "\n",
        "# --- PARTE 2: AN츼LISE DE SENTIMENTO ---\n",
        "\n",
        "print(\"\\n--- Iniciando a an치lise de sentimento dos artigos ---\")\n",
        "\n",
        "# Criando o analisador de sentimento VADER\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Fun칞칚o para aplicar a an치lise de sentimento e extrair o score compound\n",
        "def get_sentiment_compound(text):\n",
        "    if isinstance(text, str) and text.strip(): # Garante que 칠 string e n칚o vazia\n",
        "        return sia.polarity_scores(text)['compound']\n",
        "    return 0.0\n",
        "\n",
        "# Aplicando a an치lise de sentimento na coluna 'Conteudo para Analise'\n",
        "df['compound_score'] = df['Conteudo para Analise'].apply(get_sentiment_compound)\n",
        "\n",
        "# Fun칞칚o para classificar o sentimento com base no 'compound_score'\n",
        "def classify_sentiment(score):\n",
        "    if score >= 0.05:\n",
        "        return \"Positivo\"\n",
        "    elif score <= -0.05:\n",
        "        return \"Negativo\"\n",
        "    else:\n",
        "        return \"Neutro\"\n",
        "\n",
        "# Criando uma nova coluna 'sentimento' com a classifica칞칚o\n",
        "df['sentimento'] = df['compound_score'].apply(classify_sentiment)\n",
        "\n",
        "print(\"\\n--- An치lise de Sentimento Conclu칤da ---\")\n",
        "print(\"\\n--- DataFrame com Sentimento ---\")\n",
        "print(df.head())\n",
        "\n",
        "# --- PARTE 3: VISUALIZA칂츾O DOS RESULTADOS (Opcional) ---\n",
        "\n",
        "print(\"\\n--- Resumo da An치lise de Sentimento ---\")\n",
        "print(df['sentimento'].value_counts())\n",
        "\n",
        "# Sentimento por dia (se as datas foram coletadas corretamente)\n",
        "if 'Data' in df.columns and not df['Data'].isnull().all():\n",
        "    print(\"\\n--- Sentimento por Dia ---\")\n",
        "    sentimento_por_dia = df.groupby('Data')['sentimento'].value_counts().unstack(fill_value=0)\n",
        "    print(sentimento_por_dia)\n",
        "else:\n",
        "    print(\"\\nN칚o foi poss칤vel agrupar por dia, pois a coluna 'Data' est치 ausente ou vazia.\")"
      ]
    }
  ]
}